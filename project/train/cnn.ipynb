{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "images = pd.read_csv('./_annotations.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "    Unnamed: 0                                           Filepath  Weight\n0            0  ./20220430_172126_jpg.rf.3fafe29809654fd50b310...     136\n1            1  ./20220430_172126_jpg.rf.500efe03a5dfe328ca4ed...     136\n2            2  ./20220430_172126_jpg.rf.64d7d68c2db9ef8784de1...     136\n3            3  ./20220430_172126_jpg.rf.8ba840693486aa164606d...     136\n4            4  ./20220430_172126_jpg.rf.9376bc1137e185e64bb01...     136\n..         ...                                                ...     ...\n93          93  ./20220430_172634_jpg.rf.a873937c1c664a4940c19...     161\n94          94  ./20220430_172634_jpg.rf.b24154405b5441b1d7307...     161\n95          95  ./20220430_172634_jpg.rf.ba8e2086d1c9720d5637a...     161\n96          96  ./20220430_172634_jpg.rf.cbc9226afd4fedd195ed7...     161\n97          97  ./20220430_172634_jpg.rf.f8765c163c666ffaa9cd1...     161\n\n[98 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Filepath</th>\n      <th>Weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>./20220430_172126_jpg.rf.3fafe29809654fd50b310...</td>\n      <td>136</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>./20220430_172126_jpg.rf.500efe03a5dfe328ca4ed...</td>\n      <td>136</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>./20220430_172126_jpg.rf.64d7d68c2db9ef8784de1...</td>\n      <td>136</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>./20220430_172126_jpg.rf.8ba840693486aa164606d...</td>\n      <td>136</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>./20220430_172126_jpg.rf.9376bc1137e185e64bb01...</td>\n      <td>136</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>93</td>\n      <td>./20220430_172634_jpg.rf.a873937c1c664a4940c19...</td>\n      <td>161</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>94</td>\n      <td>./20220430_172634_jpg.rf.b24154405b5441b1d7307...</td>\n      <td>161</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>95</td>\n      <td>./20220430_172634_jpg.rf.ba8e2086d1c9720d5637a...</td>\n      <td>161</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>96</td>\n      <td>./20220430_172634_jpg.rf.cbc9226afd4fedd195ed7...</td>\n      <td>161</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>97</td>\n      <td>./20220430_172634_jpg.rf.f8765c163c666ffaa9cd1...</td>\n      <td>161</td>\n    </tr>\n  </tbody>\n</table>\n<p>98 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             Filepath  Weight\n93  ./20220430_172634_jpg.rf.a873937c1c664a4940c19...     161\n94  ./20220430_172634_jpg.rf.b24154405b5441b1d7307...     161\n95  ./20220430_172634_jpg.rf.ba8e2086d1c9720d5637a...     161\n96  ./20220430_172634_jpg.rf.cbc9226afd4fedd195ed7...     161\n97  ./20220430_172634_jpg.rf.f8765c163c666ffaa9cd1...     161",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Filepath</th>\n      <th>Weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>93</th>\n      <td>./20220430_172634_jpg.rf.a873937c1c664a4940c19...</td>\n      <td>161</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>./20220430_172634_jpg.rf.b24154405b5441b1d7307...</td>\n      <td>161</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>./20220430_172634_jpg.rf.ba8e2086d1c9720d5637a...</td>\n      <td>161</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>./20220430_172634_jpg.rf.cbc9226afd4fedd195ed7...</td>\n      <td>161</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>./20220430_172634_jpg.rf.f8765c163c666ffaa9cd1...</td>\n      <td>161</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = images[['Filepath','Weight']]\n",
    "images.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(images, train_size=0.7, shuffle=True, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55 validated image filenames.\n",
      "Found 13 validated image filenames.\n",
      "Found 30 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Weight',\n",
    "    target_size=(120, 120),\n",
    "    color_mode='rgb',\n",
    "    class_mode='raw',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Weight',\n",
    "    target_size=(120, 120),\n",
    "    color_mode='rgb',\n",
    "    class_mode='raw',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Weight',\n",
    "    target_size=(120, 120),\n",
    "    color_mode='rgb',\n",
    "    class_mode='raw',\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(120, 120, 3))\n",
    "x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 120, 120, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 118, 118, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 59, 59, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 57, 57, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 28, 28, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 32)               0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,425\n",
      "Trainable params: 11,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.01),\n",
    "    loss='mse'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 2610.9995 - val_loss: 611.8718\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 1211.4323 - val_loss: 1531.4377\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 744.3281 - val_loss: 497.5287\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 773.8289 - val_loss: 1333.6616\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 978.5619 - val_loss: 247.5989\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 183.3886 - val_loss: 566.5135\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 699.0227 - val_loss: 350.3643\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 334.2834 - val_loss: 251.2247\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 331.9361 - val_loss: 520.4112\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 396.3000 - val_loss: 160.8571\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 125.8708 - val_loss: 230.6940\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 315.8292 - val_loss: 231.0426\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 211.6391 - val_loss: 133.6421\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 177.0365 - val_loss: 288.6287\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 248.5004 - val_loss: 139.3489\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 142.3360 - val_loss: 151.2345\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 187.9447 - val_loss: 139.7834\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 135.5909 - val_loss: 131.4551\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 143.9613 - val_loss: 162.1361\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 145.3001 - val_loss: 103.5632\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 190ms/step - loss: 119.0188 - val_loss: 113.6122\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 130.2089 - val_loss: 103.9496\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 115.3012 - val_loss: 117.2283\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 121.8837 - val_loss: 109.7196\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 117.8057 - val_loss: 103.5808\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 116.4215 - val_loss: 103.3139\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 223ms/step - loss: 115.5219 - val_loss: 106.2539\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 115.1551 - val_loss: 107.2266\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 115.5278 - val_loss: 105.0067\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 117.2845 - val_loss: 103.2339\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 115.3660 - val_loss: 104.5529\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 114.7356 - val_loss: 107.6356\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 116.3467 - val_loss: 105.1402\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 114.1193 - val_loss: 103.1899\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 119.6446 - val_loss: 103.1049\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 114.3502 - val_loss: 112.3374\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 122.7649 - val_loss: 118.7043\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 119.1012 - val_loss: 103.0929\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 219ms/step - loss: 118.0083 - val_loss: 104.3168\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 117.4871 - val_loss: 107.0036\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 115.2110 - val_loss: 110.5067\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 117.1942 - val_loss: 105.4596\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 117.8066 - val_loss: 103.0621\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 119.4794 - val_loss: 105.2573\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 114.7582 - val_loss: 103.7230\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 115.1801 - val_loss: 103.7134\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 117.3684 - val_loss: 103.2490\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 115.1368 - val_loss: 109.3747\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 125.5189 - val_loss: 116.1666\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 120.3190 - val_loss: 103.6976\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 118.3139 - val_loss: 102.9711\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 114.0941 - val_loss: 108.4837\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 117.3664 - val_loss: 108.2277\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 115.4168 - val_loss: 102.6531\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 118.1399 - val_loss: 102.6302\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 121.0371 - val_loss: 115.0209\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 117.6057 - val_loss: 102.8611\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 131.8826 - val_loss: 102.5658\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 111.5622 - val_loss: 124.5360\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 128.8720 - val_loss: 110.1294\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 119.1503 - val_loss: 108.4578\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 122.6065 - val_loss: 105.2268\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 120.2977 - val_loss: 116.8700\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 125.9083 - val_loss: 102.3221\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 116.5575 - val_loss: 105.0597\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 114.3292 - val_loss: 103.5610\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 118.7294 - val_loss: 102.5131\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 116.7016 - val_loss: 102.5698\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 117.0218 - val_loss: 111.1577\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 120.6155 - val_loss: 117.8873\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 116.3566 - val_loss: 103.3491\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 119.0280 - val_loss: 102.3719\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 115.4726 - val_loss: 109.8506\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 119.0105 - val_loss: 104.7675\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 112.9549 - val_loss: 102.2730\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 119.4753 - val_loss: 101.8997\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 129.4673 - val_loss: 101.8613\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 118.2663 - val_loss: 120.6814\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 123.5302 - val_loss: 101.8615\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 210ms/step - loss: 133.3458 - val_loss: 108.8808\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 127.3168 - val_loss: 132.4123\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 130.0631 - val_loss: 103.8071\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 116.2219 - val_loss: 103.9239\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 117.4812 - val_loss: 106.7552\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 123.9436 - val_loss: 114.8972\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 190ms/step - loss: 120.9209 - val_loss: 105.6343\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 119.9966 - val_loss: 104.7273\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 126.9988 - val_loss: 115.8221\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 121.1674 - val_loss: 106.2849\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 129.7988 - val_loss: 102.8278\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 172.5706 - val_loss: 149.5577\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 147.3859 - val_loss: 117.7337\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 134.9147 - val_loss: 103.8775\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 117.1905 - val_loss: 124.3359\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 120.1001 - val_loss: 103.6276\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 130.0235 - val_loss: 102.3867\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 116.1853 - val_loss: 129.0316\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 131.9095 - val_loss: 102.3012\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 142.7183 - val_loss: 112.7295\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 124.7002 - val_loss: 136.7488\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 243ms/step - loss: 136.6187 - val_loss: 103.4326\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 236ms/step - loss: 132.2558 - val_loss: 113.9217\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 126.8643 - val_loss: 126.5786\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 130.0131 - val_loss: 105.3296\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 132.9270 - val_loss: 110.0009\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 127.6966 - val_loss: 120.6716\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 123.2461 - val_loss: 103.4588\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 113.2995 - val_loss: 100.8422\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 115.2068 - val_loss: 103.1970\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 122.2435 - val_loss: 105.2336\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 111.6657 - val_loss: 107.3527\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 124.9819 - val_loss: 101.2639\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 112.3228 - val_loss: 111.0047\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 118.2926 - val_loss: 104.7251\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 113.2855 - val_loss: 100.7909\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 230ms/step - loss: 130.5697 - val_loss: 100.4096\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 141.2130 - val_loss: 129.7702\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 119.3486 - val_loss: 108.9147\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 127.2034 - val_loss: 100.9620\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 182ms/step - loss: 113.3230 - val_loss: 114.3773\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 118.4119 - val_loss: 100.1722\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 199ms/step - loss: 116.2543 - val_loss: 100.6989\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 113.0739 - val_loss: 106.1275\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 114.1816 - val_loss: 102.4897\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 123.2109 - val_loss: 100.1261\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 136.8404 - val_loss: 119.8156\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 137.6001 - val_loss: 101.1356\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 116.6868 - val_loss: 110.6529\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 116.5557 - val_loss: 100.4246\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 114.3822 - val_loss: 100.0946\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 113.5403 - val_loss: 109.0150\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 115.2029 - val_loss: 100.6985\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 112.1560 - val_loss: 99.6606\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 119.4480 - val_loss: 99.8929\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 112.6704 - val_loss: 99.7621\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 117.9562 - val_loss: 100.9853\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 129.0312 - val_loss: 112.2799\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 114.3403 - val_loss: 105.3993\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 124.5811 - val_loss: 102.8740\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 113.3761 - val_loss: 101.4173\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 112.5764 - val_loss: 99.3011\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 115.1776 - val_loss: 108.5557\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 115.7665 - val_loss: 107.6168\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 113.5541 - val_loss: 99.5261\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 116.9959 - val_loss: 99.8221\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 121.9345 - val_loss: 104.2563\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 116.7799 - val_loss: 100.5889\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 190ms/step - loss: 127.9958 - val_loss: 98.9822\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 128.4387 - val_loss: 126.9626\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 211ms/step - loss: 133.0154 - val_loss: 107.9054\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 122.8187 - val_loss: 118.9335\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 126.8751 - val_loss: 107.4272\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 109.2123 - val_loss: 104.4095\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 121.2877 - val_loss: 102.9165\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 117.6085 - val_loss: 105.5235\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 114.2889 - val_loss: 100.8605\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 202ms/step - loss: 122.1218 - val_loss: 106.4178\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 113.6291 - val_loss: 118.9341\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 117.4796 - val_loss: 100.6166\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 124.9469 - val_loss: 99.0653\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 149.0556 - val_loss: 124.4928\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 146.6095 - val_loss: 116.9363\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 136.7295 - val_loss: 126.3977\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 283ms/step - loss: 131.9889 - val_loss: 98.2469\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 263ms/step - loss: 147.8189 - val_loss: 101.9355\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 1s 322ms/step - loss: 111.4823 - val_loss: 143.5028\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 134.4439 - val_loss: 99.2720\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 121.3506 - val_loss: 100.0546\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 110.4542 - val_loss: 120.5863\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 223ms/step - loss: 122.8899 - val_loss: 98.1375\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 118.2833 - val_loss: 98.8447\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 121.6954 - val_loss: 115.1000\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 208ms/step - loss: 114.0740 - val_loss: 99.8445\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 227ms/step - loss: 117.5954 - val_loss: 98.5822\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 111.7686 - val_loss: 108.6048\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 112.7136 - val_loss: 98.0519\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 113.5942 - val_loss: 98.3832\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 110.6588 - val_loss: 102.6337\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 233ms/step - loss: 115.0469 - val_loss: 98.3778\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 111.5759 - val_loss: 100.6467\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 113.5026 - val_loss: 97.5983\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 111.5538 - val_loss: 97.3792\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 121.9276 - val_loss: 99.5124\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 147.1705 - val_loss: 101.0931\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 113.4145 - val_loss: 121.0063\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 116.4338 - val_loss: 104.6821\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 124.2461 - val_loss: 103.5263\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 127.5823 - val_loss: 104.8147\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 125.1022 - val_loss: 102.5032\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 125.7153 - val_loss: 127.8763\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 213ms/step - loss: 122.2458 - val_loss: 100.9928\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 116.6699 - val_loss: 102.6267\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 111.5779 - val_loss: 99.3420\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 110.9059 - val_loss: 96.7660\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 324ms/step - loss: 111.7794 - val_loss: 97.9008\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 1s 238ms/step - loss: 109.9241 - val_loss: 104.7953\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 240ms/step - loss: 114.3004 - val_loss: 96.5966\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 113.2228 - val_loss: 99.3023\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 184ms/step - loss: 118.4109 - val_loss: 106.6993\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 313ms/step - loss: 119.1984 - val_loss: 103.1612\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data=val_images,\n",
    "    epochs=200,\n",
    "    # callbacks=[\n",
    "    #     tf.keras.callbacks.EarlyStopping(\n",
    "    #         monitor='val_loss',\n",
    "    #         patience=5,\n",
    "    #         restore_best_weights=True\n",
    "    #     )\n",
    "    # ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  # plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  # plt.ylim([0, 10])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error')\n",
    "  plt.legend()\n",
    "  plt.grid(True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Test RMSE: 8.50053\n",
      "Test R^2 Score: -0.32353\n"
     ]
    }
   ],
   "source": [
    "predicted_weight = np.squeeze(model.predict(test_images))\n",
    "true_ages = test_images.labels\n",
    "\n",
    "rmse = np.sqrt(model.evaluate(test_images, verbose=0))\n",
    "print(\"     Test RMSE: {:.5f}\".format(rmse))\n",
    "\n",
    "r2 = r2_score(true_ages, predicted_weight)\n",
    "print(\"Test R^2 Score: {:.5f}\".format(r2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null/Baseline Model Test RMSE: 7.38888\n"
     ]
    }
   ],
   "source": [
    "null_rmse = np.sqrt(np.sum((true_ages - np.mean(true_ages))**2) / len(true_ages))\n",
    "print(\"Null/Baseline Model Test RMSE: {:.5f}\".format(null_rmse))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}